{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "147adf40-c686-4ffa-9b77-1bf39ecbdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolov7 Repository Clone and Requirements Installation:\n",
    "!git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a992c40-c5c4-4758-aaa7-87f104b808ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries:\n",
    "!pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37258c6b-0a80-4e4c-9062-192b0f31fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "769bd0a6-e9f9-454c-9611-5e0068680bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7d1a2cd-adf4-44ed-8312-13cefdbdff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install telepot\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48b44bd6-ae2c-47f0-9f69-881058f27e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telepot\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3587264a-8265-421c-ad88-da8a281d7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0686216-b7a3-477f-bc01-8c5f589c3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b309fd9d-c6dc-4b7d-9e5b-16ccff3434ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f8ebd8a-e057-42e2-bc2f-907ac30154d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telegram Integration:\n",
    "token = 'xxxxxxxxxxxxxxxxxxx' # telegram token\n",
    "receiver_id = 000000000 # https://api.telegram.org/bot<TOKEN>/getUpdates\n",
    "bot = telepot.Bot(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ab26674-86ac-4cab-970e-2a57fa121695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Loading YOLOv7 Model:\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Add the directory containing the 'models' module to sys.path\n",
    "sys.path.append(r'C:\\Users\\amala\\yolov7')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights_path = 'yolov7/yolov7-w6-pose.pt'\n",
    "\n",
    "try:\n",
    "    # Load the weights\n",
    "    weights = torch.load(weights_path, map_location=device)\n",
    "    model = weights['model']\n",
    "\n",
    "    # Move the model to the device and set to eval mode\n",
    "    model = model.half().to(device)\n",
    "    _ = model.eval()\n",
    "\n",
    "    print(\"Model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {weights_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f942d28-3a32-4f73-807c-c96be30ecba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sending test message: HTTPSConnectionPool(host='api.telegram.org', port=443): Max retries exceeded with url: /bot7043918091:AAEbcubnv56WteKGv6Ua1ciRA55KN9_M-90/sendMessage (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001F2664C8B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    }
   ],
   "source": [
    "import telepot\n",
    "\n",
    "token = '7043918091:AAEbcubnv56WteKGv6Ua1ciRA55KN9_M-90'\n",
    "receiver_id = 1103585699\n",
    "\n",
    "bot = telepot.Bot(token)\n",
    "\n",
    "# Test the connection by sending a test message\n",
    "try:\n",
    "    bot.sendMessage(receiver_id, \"Test message from your bot\")\n",
    "    print(\"Test message sent successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error sending test message: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1a3b340-479b-40bc-828f-4ad6c4588972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Processing:\n",
    "threshold=10\n",
    "video_path = 'video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error while trying to read video. Please check the path again.')\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "vid_write_image = letterbox(cap.read()[1], frame_width, stride=64, auto=True)[0]\n",
    "resize_height, resize_width = vid_write_image.shape[:2]\n",
    "out_video_name = f\"{video_path.split('/')[-1].split('.')[0]}\"\n",
    "# Output Video Generation:\n",
    "out = cv2.VideoWriter(f\"{out_video_name}_keypoint.mp4\",\n",
    "                      cv2.VideoWriter_fourcc(*'mp4v'), 30,\n",
    "                      (resize_width, resize_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2eae41-457e-45e0-9e60-7f3ecb3c9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "fall_detected = False  # Flag to track fall detection\n",
    "# Convert model weights to float before processing\n",
    "model.to(torch.float32)\n",
    "\n",
    "previous_shoulder_height = None\n",
    "previous_foot_height = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    print(\"Frame {} Processing\".format(frame_count))\n",
    "    frame_count += 1\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    orig_image = frame\n",
    "    image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "    image = letterbox(image, frame_width, stride=64, auto=True)[0]\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = torch.tensor(np.array([image.numpy()])).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(image)\n",
    "\n",
    "    output = output.float()\n",
    "    output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "    output = output_to_keypoint(output)\n",
    "    im0 = image[0].permute(1, 2, 0) * 255\n",
    "    im0 = im0.cpu().numpy().astype(np.uint8)\n",
    "    im0 = cv2.cvtColor(im0, cv2.COLOR_RGB2BGR)\n",
    "# Fall Detection Message Handling:\n",
    "    fall_detected = False  # Reset fall detection flag for each frame\n",
    "\n",
    "    for idx in range(output.shape[0]):\n",
    "        xmin, ymin = (output[idx, 2] - output[idx, 4] / 2), (output[idx, 3] - output[idx, 5] / 2)\n",
    "        xmax, ymax = (output[idx, 2] + output[idx, 4] / 2), (output[idx, 3] + output[idx, 5] / 2)\n",
    "\n",
    "        # Check for a significant decrease in shoulder and foot heights\n",
    "        shoulder_height = output[idx][23]\n",
    "        foot_height = output[idx][53]\n",
    "        if previous_shoulder_height is not None and previous_foot_height is not None:\n",
    "            if (previous_shoulder_height - shoulder_height > threshold) and (previous_foot_height - foot_height > threshold):\n",
    "                fall_detected = True\n",
    "\n",
    "        print(\"Shoulder height:\", shoulder_height)\n",
    "        print(\"Foot height:\", foot_height)\n",
    "\n",
    "        if fall_detected:\n",
    "            cv2.rectangle(im0, (int(xmin), int(ymin)), (int(xmax), int(ymax)), color=(0, 0, 255), thickness=5, lineType=cv2.LINE_AA)\n",
    "            cv2.putText(im0, 'Person Fell down', (11, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, [0, 0, 255], thickness=3, lineType=cv2.LINE_AA)\n",
    "            print(\"fall_detected value:\", fall_detected)\n",
    "\n",
    "    # Update previous heights\n",
    "    previous_shoulder_height = shoulder_height\n",
    "    previous_foot_height = foot_height\n",
    "\n",
    "    if fall_detected:\n",
    "        try:\n",
    "            bot.sendMessage(receiver_id, \"Person Fall Detected\")\n",
    "            print(\"Fall detection message sent successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error sending fall detection message: {e}\")\n",
    "        fall_detected = False  # Reset the flag after sending the message\n",
    "\n",
    "    out.write(im0)\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c052a73-0a59-446d-9fd1-fd36e70ca29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
